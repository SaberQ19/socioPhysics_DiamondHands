{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks\n",
    "This notebook shows how to treat the stock prices and make some simple analyses of financial time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read and handle a csv file\n",
    "Here we open a csv (comma separated values) file containing the stock prices (in this case, daily close prices). We first get the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sociophysicsDataHandler import SociophysicsDataHandler\n",
    "\n",
    "student_config = True\n",
    "\n",
    "file_target = 'asdz/platform2.2/20200428/ASDZ_Perron2.2_2020042815_trajectorie.parquet' \n",
    "\n",
    "if student_config:\n",
    "    dh = SociophysicsDataHandler()\n",
    "    dh.fetch_prorail_data_from_path(file_target)\n",
    "else:\n",
    "    webdav_basepath='/Crowdflow (Projectfolder)/ProRail_USE_LL_data'\n",
    "    dh = SociophysicsDataHandler(basepath=webdav_basepath)\n",
    "    \n",
    "    dh.fetch_prorail_data_from_path(file_target)\n",
    "                           # ,basepath=webdav_basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dh.fetch_econophysics_data_from_path(\"econophysics/prices/daily_close_prices.csv\")\n",
    "prices = dh.df\n",
    "prices.index = pd.to_datetime(prices.index) # to be sure that the index is in the pandas DateTime format\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot stock daily prices between a certain time range\n",
    "Define the time range and the stock we want to show, and plot the corresponding close prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "stock = 'GME'\n",
    "start_month = '2018-01'\n",
    "end_month = '2022-07'\n",
    "prices_toPlot = prices[[stock]][start_month:end_month]\n",
    "prices_toPlot.plot()\n",
    "pl.xlabel('Time', fontsize=14)\n",
    "pl.ylabel('Price (USD)', fontsize=14)\n",
    "pl.title(stock + ', close price', fontsize=14)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily returns\n",
    "Calculate daily returns and their statistics. Daily returns are percentage changes between consecutive prices. For example, if yesterday's price was 150 USD and today's price is 152 USD, then the daily return is (152-150)/150 = 0.013, i.e. 1.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = prices.pct_change()\n",
    "print('The mean daily returns are:')\n",
    "print(rets.mean())\n",
    "print('The standard deviation of the daily returns are:')\n",
    "print(rets.std())\n",
    "# standard deviations of daily returns show the level of fluctuations of the stocks;\n",
    "# higher standard deviation implies higher stock volatility (see \"Calculate stock volatility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and grouping\n",
    "We can filter the returns dataframe based on some condition (for example, the magnitude of the returns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_threshold = 2 # we will select only the days with daily return larger than 2%\n",
    "stock = 'AAPL'\n",
    "rets_percent = 100*rets #  transform returns into percent returns to increase readability\n",
    "rets_percent_large = rets_percent[[stock]][rets_percent > return_threshold] # in the square brackets, we set the condition\n",
    "rets_percent_small = rets_percent[[stock]][rets_percent < -return_threshold]\n",
    "rets_percent_large.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate stock volatility\n",
    "From the stock prices and returns we can calculate the volatility, i.e. the average fluctuations of the stock in the last n days. The volatility represents the risk associated to the financial object: the higher the volatility, the riskier the security. In mathematical terms, it is nothing but the weighted variance of the stock returns multiplied by a factor, as shown in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def volaCalc2(x, w): # x is your pandas dataframe showing the close-close returns and w is a vector of weights\n",
    "    # in this case, we calculate the volatility on 65 trading days, and we weight the last 5 days twice w.r.t. to the others:\n",
    "    w = np.append(np.repeat(1, 60),np.repeat(2, 5)) \n",
    "    ttt=datetime.datetime.now() # check time\n",
    "    \n",
    "    n_col = x.shape[1]\n",
    "    n_row = x.shape[0]\n",
    "    n_w = len(w)\n",
    "    s_w = sum(w)\n",
    "    tmp_mean = np.tile(np.nan, (n_row, n_col))\n",
    "    vola = np.tile(np.nan, (n_row, n_col))\n",
    "    x_array = x.values # transform pandas into array\n",
    "    \n",
    "    for j in range(0,n_col): # loop on columns\n",
    "        tmpcol=x_array[:,j];\n",
    "        for i in range(0,n_row): # loop on rows\n",
    "            if i >= n_w:\n",
    "                tmp_mean[i,j] = sum((w*tmpcol[i+1-n_w:i+1]))/s_w\n",
    "                vola[i,j] = sum(w*(tmpcol[i+1-n_w:i+1]-tmp_mean[i,j])*(tmpcol[i+1-n_w:i+1]-tmp_mean[i,j]))/(s_w-1) #weighted variance\n",
    "                \n",
    "    vola = pd.DataFrame(vola, index = x.index, columns=x.columns)\n",
    "    print(' total time: '+str((datetime.datetime.now() - ttt).seconds + (datetime.datetime.now() - ttt).microseconds/1E6) + ' s')        \n",
    "    return(vola)\n",
    "\n",
    "weights = np.append(np.repeat(1, 60),np.repeat(2, 5))\n",
    "volatility_daily = np.sqrt(volaCalc2(rets, weights)) # compute the square root of the variance\n",
    "# this is the daily volatility; usually, though, the volatility is presented in annualized terms \n",
    "# assuming there are 252 trading days in a year, we therefore multiply the daily volatility by the square root of 252:\n",
    "volatility = np.sqrt(252)*volatility_daily\n",
    "print('The annualized volatility of the last 5 days of the dataset is:')\n",
    "print(100*volatility.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time zones\n",
    "One of the crucial aspects, when dealing with financial time series, is paying attention to the time zones in which the data are expressed. This is important if we want to correctly match the Reddit database (where times are expressed in UTC a.k.a. GMT) with the stock database (expressed in New York time). Here we show how to transform the latter into UTC time. This issue is only present when dealing with intraday prices (in this case, at hourly resolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.fetch_econophysics_data_from_path(\"econophysics/prices/hourly_prices.csv\")\n",
    "prices_hour = dh.df\n",
    "prices_hour.index = pd.to_datetime(prices_hour.index) # to be sure that the index is in the pandas DateTime format\n",
    "print(prices_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the times you see in the index of prices_hour are expressed in New York time (American Eastern Time) \n",
    "# American Eastern Time is defined as UTC-5 in autumn and winter, and UTC-4 in spring and summer (daylight saving)\n",
    "import datetime as dt\n",
    "from dateutil import tz # library to treat timezones\n",
    "NYC = tz.gettz('America/New_York') # define the New York timezone\n",
    "\n",
    "# we begin with a single time as an example; let's take the 13th entry in the prices dataframe:\n",
    "i = 13\n",
    "dat = str(prices_hour.index[i].date())\n",
    "print('The considered date is:', dat)\n",
    "print('In particular, we are considering the index:', prices_hour.index[i], 'in New York time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute the offset between New York time and UTC (the time we want to use) on that date:\n",
    "dt1 = dt.datetime(int(dat[0:4]), int(dat[5:7]),int(dat[8:10]), tzinfo=NYC)\n",
    "UTC_lag = dt1.utcoffset() / dt.timedelta(hours=1)\n",
    "print('On', dat, 'the offset is', UTC_lag, 'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can actually transform the time index into UTC:\n",
    "new_index = prices_hour.index[i] - pd.Timedelta(hours=UTC_lag)\n",
    "print('The 13th index in New York time is:', prices_hour.index[i])\n",
    "print('The 13th index in UTC time is:', new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we do the same for a winter day, then we see that the offset is in that case 5 hours\n",
    "i = 2000\n",
    "dat = str(prices_hour.index[i].date())\n",
    "dt1 = dt.datetime(int(dat[0:4]), int(dat[5:7]),int(dat[8:10]), tzinfo=NYC)\n",
    "UTC_lag = dt1.utcoffset() / dt.timedelta(hours=1)\n",
    "print('On', dat, 'the offset is', UTC_lag, 'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can therefore transform the whole dataframe based on this rule:\n",
    "prices_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index_list = []\n",
    "for i in range(len(prices_hour)):\n",
    "    # for each index, make the previous index transformation:\n",
    "    old_index = prices_hour.index[i]\n",
    "    dat = str(old_index.date())\n",
    "    dt1 = dt.datetime(int(dat[0:4]), int(dat[5:7]),int(dat[8:10]), tzinfo=NYC)\n",
    "    UTC_lag = dt1.utcoffset() / dt.timedelta(hours=1)\n",
    "    new_index = prices_hour.index[i] - pd.Timedelta(hours=UTC_lag)\n",
    "    # attach the UTC index to the new index list:\n",
    "    new_index_list.append(new_index)\n",
    "    \n",
    "# set the new UTC index to the prices_hour dataframe:\n",
    "prices_hour.index = new_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
